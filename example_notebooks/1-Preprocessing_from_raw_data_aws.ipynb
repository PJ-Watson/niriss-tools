{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing from MAST data\n",
    "\n",
    "This notebook covers processing the data from `*_uncal.fits` files, through to creating drizzled mosaics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# This is currently a necessity; newer pipeline reductions do not work well with grizli\n",
    "os.environ[\"CRDS_CONTEXT\"] = \"jwst_1173.pmap\"\n",
    "\n",
    "# Replace the following lines with your preferred directory structure\n",
    "root_dir = Path(os.getenv(\"ROOT_DIR\"))\n",
    "\n",
    "# The directory containing the MAST downloads\n",
    "uncal_dir = root_dir / \"archival\" / \"MAST_2024-10-03T09_25_33.967Z\" / \"JWST\"\n",
    "\n",
    "# The output directory\n",
    "raw_output_dir = root_dir / \"archival\" / \"JWST\" / \"A2744_CTX_1173\"\n",
    "raw_output_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by processing the `*_uncal.fits` files using the `jwst` pipeline package, to produce the `*_rate.fits` files that `grizli` uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jwst.pipeline import Detector1Pipeline\n",
    "\n",
    "pipe = Detector1Pipeline()\n",
    "\n",
    "pipe.save_results = True\n",
    "pipe.output_dir = str(raw_output_dir)\n",
    "pipe.jump.maximum_cores = \"8\"\n",
    "\n",
    "for file in uncal_dir.glob(\"*uncal.fits\"):\n",
    "    output_filename = (raw_output_dir / file.name).with_stem(\n",
    "        file.stem.replace(\"_uncal\", \"_rate\")\n",
    "    )\n",
    "    if output_filename.is_file():\n",
    "        print(f\"{file.name} exists.\")\n",
    "        continue\n",
    "    else:\n",
    "        pipe.output_file = output_filename.stem.strip(\"_rate\")\n",
    "        pipe.run(\n",
    "            str(file),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import all the necessary packages, and setup the `grizli` directory structure. For further details on installing and configuring `grizli`, refer to the [dedicated installation instructions](https://grizli.readthedocs.io/en/latest/grizli/install.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, logging\n",
    "from astropy.io import fits\n",
    "import grizli\n",
    "from grizli import utils, prep, jwst_utils, multifit\n",
    "from grizli.pipeline import auto_script\n",
    "\n",
    "print(\"Grizli version: \", grizli.__version__)\n",
    "\n",
    "# Quiet JWST log warnings\n",
    "jwst_utils.QUIET_LEVEL = logging.INFO\n",
    "jwst_utils.set_quiet_logging(jwst_utils.QUIET_LEVEL)\n",
    "\n",
    "root_name = \"glass-a2744\"\n",
    "\n",
    "# Setup the grizli directory structure\n",
    "grizli_home_dir = root_dir / \"2024_08_16_A2744_v4\" / \"grizli_home\"\n",
    "\n",
    "grizli_home_dir.mkdir(exist_ok=True, parents=True)\n",
    "(grizli_home_dir / \"Prep\").mkdir(exist_ok=True)\n",
    "(grizli_home_dir / \"RAW\").mkdir(exist_ok=True)\n",
    "(grizli_home_dir / \"visits\").mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `grizli` association files in our processing. If our observations did not have these files (e.g. PASSAGE), it would be necessary to create them; the functions in `grizli.aws` require them. \n",
    "\n",
    "We also copy the `*_rate.fits` files to the visit directories. If we skip this step, `grizli` will automatically download the `rate` files from MAST, which will typically have been processed with the most up-to-date CRDS context. At some point in the future, this may even be desirable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(grizli_home_dir / \"visits\")\n",
    "\n",
    "from grizli import utils\n",
    "from grizli.aws import visit_processor\n",
    "\n",
    "# Cluster coordinates\n",
    "ra, dec = 3.58641, -30.39997\n",
    "\n",
    "# Self explanatory\n",
    "proposal_id = 1324\n",
    "\n",
    "# search radius, arcmin\n",
    "radius = 1\n",
    "\n",
    "QUERY_URL = \"https://grizli-cutout.herokuapp.com/assoc?coord={ra},{dec}&arcmin={radius}&output=csv\"\n",
    "\n",
    "assoc_query = utils.read_catalog(\n",
    "    QUERY_URL.format(ra=ra, dec=dec, radius=radius), format=\"csv\"\n",
    ")\n",
    "\n",
    "nis = (assoc_query[\"instrument_name\"] == \"NIRISS\") & (\n",
    "    assoc_query[\"proposal_id\"] == proposal_id\n",
    ")\n",
    "\n",
    "print(\n",
    "    assoc_query[\n",
    "        \"assoc_name\", \"target\", \"proposal_id\", \"filter\", \"instrument_name\", \"status\"\n",
    "    ][nis]\n",
    ")\n",
    "\n",
    "EXPOSURE_API = \"https://grizli-cutout.herokuapp.com/exposures?associations={assoc}\"\n",
    "\n",
    "for assoc in assoc_query[\"assoc_name\"][nis]:\n",
    "    if not (grizli_home_dir / assoc / \"Prep\").is_dir():\n",
    "\n",
    "        exp = utils.read_catalog(EXPOSURE_API.format(assoc=assoc), format=\"csv\")\n",
    "\n",
    "        # Make all the directories\n",
    "        assoc_dir = grizli_home_dir / \"visits\" / assoc\n",
    "        (assoc_dir / \"RAW\").mkdir(exist_ok=True, parents=True)\n",
    "        (assoc_dir / \"Persistence\").mkdir(exist_ok=True, parents=True)\n",
    "        (assoc_dir / \"Extractions\").mkdir(exist_ok=True, parents=True)\n",
    "        (assoc_dir / \"Prep\").mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        # Only copy files if this visit hasn't been processed yet\n",
    "        if len([*(assoc_dir / \"Prep\").glob(\"*drz_sci.fits\")]) == 0:\n",
    "            for filename in exp[\"dataset\"]:\n",
    "                try:\n",
    "                    shutil.copy(\n",
    "                        raw_output_dir / f\"{filename}_rate.fits\", assoc_dir / \"RAW\"\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    print(f\"{filename} not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the `*_rate.fits` files with the default parameters. If a non-standard processing is desired (e.g. skipping the iterative alignment), this is the place to change things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for assoc in assoc_query[\"assoc_name\"][nis]:\n",
    "    if len([*(grizli_home_dir / \"visits\" / assoc / \"Prep\").glob(\"*drz_sci.fits\")]) == 0:\n",
    "        _ = visit_processor.process_visit(\n",
    "            assoc,\n",
    "            clean=False,\n",
    "            sync=False,\n",
    "            with_db=False,\n",
    "            other_args={\n",
    "                \"CRDS_CONTEXT\": os.environ[\"CRDS_CONTEXT\"],\n",
    "                \"mosaic_drizzle_args\": {\"context\": os.environ[\"CRDS_CONTEXT\"]},\n",
    "            },\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Directory {assoc} found, local preprocesing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(grizli_home_dir / \"Prep\")\n",
    "\n",
    "# Symlink preprocessed exposure files here\n",
    "for assoc in assoc_query['assoc_name'][nis]:\n",
    "    !ln -sf ../visits/{assoc}/Prep/*rate.fits . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to make drizzled mosaics from all of the processed files in each filter. For NIRISS, this function creates the mosaics with the `n-clear` filter suffix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.wcs import WCS\n",
    "\n",
    "files = [str(s) for s in (grizli_home_dir / \"Prep\").glob(\"*rate.fits\")]\n",
    "files.sort()\n",
    "res = visit_processor.res_query_from_local(files=files)\n",
    "is_grism = np.array([\"GR\" in filt for filt in res[\"filter\"]])\n",
    "\n",
    "# Mosaic WCS that contains the exposures, but could come from somewhere else\n",
    "hdu = utils.make_maximal_wcs(\n",
    "    files=files, pixel_scale=0.03, pad=6, get_hdu=True, verbose=False\n",
    ")\n",
    "\n",
    "ref_wcs = WCS(hdu.header)\n",
    "\n",
    "_ = visit_processor.cutout_mosaic(\n",
    "    root_name,\n",
    "    res=res[~is_grism],  # Pass the exposure information table for the direct images\n",
    "    ir_wcs=ref_wcs,\n",
    "    half_optical=False,  # Otherwise will make JWST exposures at half pixel scale of ref_wcs\n",
    "    kernel=\"square\",  # Drizzle parameters\n",
    "    pixfrac=0.8,\n",
    "    clean_flt=False,  # Otherwise removes \"rate.fits\" files from the working directory!\n",
    "    s3output=None,\n",
    "    make_exptime_map=False,\n",
    "    weight_type=\"jwst\",\n",
    "    skip_existing=False,\n",
    "    context=os.environ[\"CRDS_CONTEXT\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want a stacked mosaic from all of the filters, we need a bit of a work around. The `grizli` processing steps above create separate `*_visits.yaml` files for each visit, and so we need to combine them into a single file. This allows us to use the older `grizli.pipeline.auto_script` functions to create a combined mosaic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grizli.pipeline import auto_script\n",
    "from astropy.table import vstack\n",
    "\n",
    "visits, groups, info = [], [], None\n",
    "for assoc in assoc_query[nis][\"assoc_name\"]:\n",
    "    v, g, i = auto_script.load_visits_yaml(\n",
    "        grizli_home_dir / \"visits\" / assoc / \"Prep\" / f\"{assoc}_visits.yaml\"\n",
    "    )\n",
    "    for j, v_j in enumerate(v):\n",
    "        v[j][\"footprints\"] = [fp for fps in v_j[\"footprints\"] for fp in fps]\n",
    "    for j, g_j in enumerate(g):\n",
    "        for img_type in g_j.keys():\n",
    "            try:\n",
    "                g[j][img_type][\"footprints\"] = [\n",
    "                    fp for fps in g_j[img_type][\"footprints\"] for fp in fps\n",
    "                ]\n",
    "            except:\n",
    "                print(g[j])\n",
    "\n",
    "    visits.extend(v)\n",
    "    groups.extend(g)\n",
    "    if info is None:\n",
    "        info = i\n",
    "    else:\n",
    "        info = vstack([info, i])\n",
    "\n",
    "auto_script.write_visit_info(visits, groups, info, root_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the NIRISS suffix on the filter combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_script.make_filter_combinations(\n",
    "    root_name,\n",
    "    filter_combinations={\"ir\": [\"F115WN-CLEAR\", \"F150WN-CLEAR\", \"F200WN-CLEAR\"]},\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.12_GLASS_pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
